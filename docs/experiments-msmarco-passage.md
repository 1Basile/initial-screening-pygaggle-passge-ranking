# PyGaggle: Neural Baselines on [MS MARCO Passage Retrieval](https://github.com/microsoft/MSMARCO-Passage-Ranking)

This page contains instructions for running various neural reranking baselines on the MS MARCO *passage* ranking task. 
Note that there is also a separate [MS MARCO *document* ranking task](experiments-msmarco-doc.md).

Prior to running this, we suggest looking at our first-stage [BM25 ranking instructions](https://github.com/castorini/anserini/blob/master/docs/experiments-msmarco-passage.md).
We rerank the BM25 run files that contain ~1000 passages per query.

Keeping computational resources in mind, our instructions primarily focus on a 1005 query subset of MS MARCO dev set. 
Running the instructions with the entire MS MARCO dev set should give about the same results as that in the corresponding paper. 

*Note: Run the following instructions at root of this repo.*

## Data Prep

We're first going to download the files corresponding to the 1005 query subset. The run file is generated by following the BM25 ranking instructions. We'll store the files related to this run in the `runs` directory.

```
wget https://www.dropbox.com/s/wz89rag7brcgt8v/msmarco_ans_medium.zip -P data
```

To confirm, `msmarco_ans_medium.zip` should have MD5 checksum of `1119afbdee29eb0a9a56bc6701127a84`.

Next, we extract the contents of the zip file into runs. 

```
unzip msmarco_ans_medium.zip -d data
```

We can evaluate the first-stage retrieved documents using the official MS MARCO evaluation script.

```
python3 evaluate/msmarco/msmarco_eval.py data/msmarco_ans_medium/qrels.dev.small.tsv data/msmarco_ans_medium/run.dev.small.tsv
```

And the output should be:

```
#####################
MRR @10: 0.1905808260285872
QueriesRanked: 1005
#####################
```


